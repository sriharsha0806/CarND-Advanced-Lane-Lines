{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The goals/steps of this project are the following:\n",
    ". Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    ". Apply a distortion correction to raw images.\n",
    ". Use color transforms, gradients, etc., to create a threshold binary image.\n",
    ". Detect lane pixels and fit to find the lane boundary\n",
    ". Determine the curvature of the lane and vehicle position with respect to center.\n",
    ". Warp the detected lane boundaries back onto the original image.\n",
    ". Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import glob\n",
    "import pickle\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display \n",
    "from IPython.display import Image\n",
    "from ipywidgets import interactive, interact, fixed\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Calibrating camera\n",
    "Steps involved in camera calibration:\n",
    "i. Arrays to store object pointsand image points from all the images\n",
    "ii. convert to grayscale\n",
    "iii. Find chess board corners\n",
    "iv. If corners are found add image points and object points\n",
    "\"\"\"\n",
    "def camera_calibration(images, nx, ny):\n",
    "    # Arrays to store object points and image points\n",
    "    objpoints = [] # 3D points in real world space\n",
    "    imgpoints = [] # 2D points i image plane\n",
    "    # Prepare object points by creating 9X6 points in  array each with 3 columns for the x,y,z coordinates of each corner\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    # Use numpy mgrid function to generate the coordinates \n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "    \n",
    "    for image in images:\n",
    "        img = mpimg.imread(image)\n",
    "        \n",
    "        # convert image to grayscale\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "        #print(ret)\n",
    "        # If corners are found, add image points and object points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            # draw and display the corners\n",
    "            # img = cv2.drawChessboardCorners(img, (nx,ny),corners, ret)\n",
    "            # plt.imshow(img)\n",
    "            \n",
    "    return cv2.calibrateCamera(objpoints, imgpoints, img.shape[0:2], None, None)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nx = 9\n",
    "ny = 6\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "#Checking file directory\n",
    "#img = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "#plt.figure()\n",
    "#plt.imshow(img)\n",
    "#calibrate the camera\n",
    "ret, mtx,dist, rvecs, tvecs = camera_calibration(images,nx,ny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "global mtx,dist,nx,ny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Correcting the distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def camera_undistort(img, mtx, dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f73a2ef5dd8>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform distortion correction on one camera calibration image\n",
    "img = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "# Test undistortion on image\n",
    "dst = camera_undistort(img, mtx, dist)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Correcting the distortion', fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform distortion correction on test images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "for image in images:\n",
    "    img = mpimg.imread(image)    \n",
    "    # Test undistortion on image\n",
    "    dst = camera_undistort(img, mtx, dist)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('correcting the distortion', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image, number of x and y points, \n",
    "# camera matrix and distortion coefficients\n",
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Convert undistorted image to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    # Search for corners in the grayscaled image\n",
    "    # ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    # global warped\n",
    "    # if ret == True:\n",
    "    # If we found corners, draw them! (just for fun)\n",
    "    h,w = gray.shape\n",
    "    # cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "    # Choose offset from image corners to plot detected corners\n",
    "    # This should be chosen to present the result at the proper aspect ratio\n",
    "    # For source points I'm grabbing the outer four detected corners\n",
    "    src = np.float32([[570,465],[707,465],[258,682],[1049,682]])\n",
    "    # For destination points, I'm arbitrarily choosing some points to be\n",
    "    # a nice fit for displaying our warped result \n",
    "    # again, not exact, but close enough for our purposes\n",
    "    dst = np.float32([[450,0],[w-450,0],[450,h],[w-450,h]])\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    return cv2.warpPerspective(undist, M, gray.shape[::-1], flags = cv2.INTER_LINEAR), M, Minv\n",
    "\n",
    "# Return the resulting image and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f739d3fcac8>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform distortion correction on one test image image\n",
    "img = mpimg.imread('test_images/test3.jpg')\n",
    "# Test the corners_unwarp on test image\n",
    "unwarp_img, M, Minv = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "# Minv is used at the end for projecting the path onto real world\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(unwarp_img)\n",
    "ax2.set_title('Unwarped_Image', fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"    \n",
    "    shape = img.shape\n",
    "    #vertices = np.array([[(0,0),(shape[1],0),(shape[1],0),(6*shape[1]/7,shape[0]),\n",
    "    #                 (shape[1]/7,shape[0]), (0,0)]],dtype=np.int32)\n",
    "    vertices = np.array([[(400,720),(1000,720),(1000,0),(400,0)]], dtype=np.int32)\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "# Perform distortion correction on one test image image\n",
    "img = mpimg.imread('test_images/test3.jpg')\n",
    "# Test the corners_unwarp on test image\n",
    "unwarp_img, M, Minv = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "ROI = region_of_interest(unwarp_img)\n",
    "# Minv is used at the end for projecting the path onto real world\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(ROI)\n",
    "ax2.set_title('unwarped_img_region_of_interest', fontsize=30)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Applying sobel operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "# Note: calling your function with orient='x', thresh_min=5, thresh_max=100\n",
    "# should produce output like the example image shown above this quiz.\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=25, thresh_max=210):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    # binary_output = np.copy(img) # Remove this line\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.debug>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug(min_thresh=20, max_thresh=250):\n",
    "    # Run the function\n",
    "    grad_binary = abs_sobel_thresh(unwarp_img, orient='x', thresh_min=min_thresh, thresh_max=max_thresh)\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(unwarp_img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(grad_binary, cmap='gray')\n",
    "    ax2.set_title('Thresholded Gradient', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "interact(debug, min_thresh=(0,255), max_thresh=(0,255))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lab_thresh(img, thresh_min=195, thresh_max=255):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    lab = lab[:,:,2]\n",
    "    # don't normalize if there are no yellows in the image\n",
    "    if np.max(lab) > 175:\n",
    "        lab = lab*(255/np.max(lab))\n",
    "    binary_output = np.zeros_like(lab)\n",
    "    binary_output[((lab > thresh_min)&(lab<thresh_max))] = 1    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.debug>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug(min_thresh=195, max_thresh=255):\n",
    "    lab_binary = lab_thresh(unwarp_img, thresh_min=min_thresh, thresh_max=max_thresh)\n",
    "     # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(unwarp_img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(lab_binary, cmap='gray')\n",
    "    ax2.set_title('lab_B binary channel', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "interact(debug, min_thresh=(0,255),max_thresh=(0,255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LUV_thresh(img, thresh_min=140, thresh_max=255):\n",
    "    luv = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    luv = luv[:,:,0]\n",
    "    binary_output = np.zeros_like(luv)\n",
    "    binary_output[((luv > thresh_min)&(luv<thresh_max))] = 1    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.debug>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug(min_thresh=140, max_thresh=255):\n",
    "    luv_binary = LUV_thresh(unwarp_img, thresh_min=min_thresh, thresh_max=max_thresh)\n",
    "     # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(unwarp_img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(luv_binary, cmap='gray')\n",
    "    ax2.set_title('luv_l binary channel', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "interact(debug, min_thresh=(0,255),max_thresh=(0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=9, mag_thresh_min=30, mag_thresh_max = 100):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Calculate the magnitude \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "     # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh_min) & (gradmag <= mag_thresh_max)] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.debug>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug(kernel_size=3, min_thresh=11, max_thresh=100):\n",
    "    # Run the function\n",
    "    mag_binary = mag_thresh(unwarp_img, sobel_kernel=kernel_size, mag_thresh_min = min_thresh, mag_thresh_max = max_thresh)\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(unwarp_img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(mag_binary, cmap='gray')\n",
    "    ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "interact(debug, kernel_size=(1,11,2), min_thresh=(0,255),max_thresh=(0,255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function that applies Sobel x and y, \n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(img, sobel_kernel=15, thresh_min=0.70, thresh_max = 1.30):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    # binary_output = np.copy(img) # Remove this line\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh_min) & (absgraddir <= thresh_max)] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.debug>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug(kernel_size=15, min_thresh=0.7, max_thresh=1.30):\n",
    "    # Run the function\n",
    "    dir_binary = dir_threshold(unwarp_img, sobel_kernel=kernel_size, thresh_min=min_thresh, thresh_max = max_thresh)\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(unwarp_img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(dir_binary, cmap='gray')\n",
    "    ax2.set_title('Thresholded Grad. Dir.', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "interact(debug, kernel_size=(1,21,2),min_thresh=(0,np.pi/2,0.01),max_thresh=(0,np.pi/2,0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hls_channel(img, channel_index = 2, thresh_min = 90,thresh_max = 255):\n",
    "    # Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    # Extract the desired channel\n",
    "    channel = hls[:,:,channel_index]\n",
    "    \n",
    "    # Apply the threshold\n",
    "    binary_s = np.zeros_like(channel)\n",
    "    binary_s[(channel>=thresh_min)&(channel<=thresh_max)]=1\n",
    "    return binary_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.debug>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug(name_channel=2, min_thresh=90, max_thresh=255):\n",
    "    binary_s = hls_channel(unwarp_img, channel_index = name_channel, thresh_min = min_thresh, thresh_max = max_thresh)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(unwarp_img,cmap = 'gray')\n",
    "    ax1.set_title('test Image', fontsize=30)\n",
    "    ax2.imshow(binary_s,cmap = 'gray')\n",
    "    ax2.set_title(str(name_channel)+'channel of hls Binary Image', fontsize=30)\n",
    "    \n",
    "interact(debug,name_channel=(0,2,1), min_thresh = (0,255),max_thresh = (0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# currently using only s channel as mentioned by instructor threshold = (90,255).\n",
    "# I am also using H channel thresh=(15,106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "\"\"\"\n",
    "Functions\n",
    "i. camera_undistort(img, mtx, dist)\n",
    "ii.corners_unwarp(img, nx, ny, mtx, dist)\n",
    "iii. abs_sobel_thresh(img, orient='x', thresh_min=25, thresh_max=210\n",
    "iv.mag_thresh(img, sobel_kernel=9, mag_thresh_min=30, mag_thresh_max = 100)\n",
    "v. dir_threshold(img, sobel_kernel=15, thresh_min=0.70, thresh_max = 1.30)\n",
    "vi. hls_channel(img, channel_index = 2, thresh_min = 90,thresh_max = 255)\n",
    "\"\"\"\n",
    "def pipeline(image):\n",
    "    img = camera_undistort(image,mtx,dist)\n",
    "    unwarp_img, M, Minv = corners_unwarp(img,nx,ny,mtx,dist)\n",
    "    unwarp_img = region_of_interest(unwarp_img)\n",
    "    s_channel = hls_channel(unwarp_img)\n",
    "    l_channel = hls_channel(unwarp_img, channel_index=1, thresh_min=220,thresh_max=255)\n",
    "    h_channel = hls_channel(unwarp_img,channel_index = 0, thresh_min = 25, thresh_max = 90)\n",
    "    sobelAbs = abs_sobel_thresh(unwarp_img)\n",
    "    sobelMag = mag_thresh(unwarp_img)\n",
    "    sobelDir = dir_threshold(unwarp_img)\n",
    "    lab = lab_thresh(unwarp_img)\n",
    "    LUV = LUV_thresh(unwarp_img)\n",
    "    combo = np.zeros_like(lab)\n",
    "    #combo[((s_channel==1)|(h_channel==1))|((sobelAbs==1)|(sobelMag==1)|(lab==1)|(LUV==1))]=1\n",
    "          #|(sobelDir==1)]=1\n",
    "    #combo[((lab==1)|(LUV==1))&(s_channel==1)]=1\n",
    "    #combo[(lab==1)|(s_channel==1)]=1\n",
    "    combo[(lab==1)|(l_channel==1)]=1\n",
    "    \n",
    "    return combo, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform the combination of all features on test images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "for image in images:\n",
    "    img = mpimg.imread(image)    \n",
    "    # Test undistortion on image\n",
    "    combination, Minv = pipeline(img)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(combination,cmap='gray')\n",
    "    ax2.set_title('correction', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f73a4ac7240>]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = mpimg.imread('test_images/test3.jpg')\n",
    "combination, Minv = pipeline(image)\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.figure()\n",
    "plt.imshow(combination,cmap='gray')\n",
    "plt.figure()\n",
    "histogram = np.sum(combination[combination.shape[0]//2:,:], axis=0)\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define method to fit polynomial to binary image with lines extracted, using sliding window\n",
    "def sliding_window(img):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    quarter_point = np.int(midpoint//2)\n",
    "    # Previously the left/right base was the max of the left/right half of the histogram\n",
    "    # this changes it so that only a quarter of the histogram (directly to the left/right) is considered\n",
    "    leftx_base = np.argmax(histogram[quarter_point:midpoint]) + quarter_point\n",
    "    rightx_base = np.argmax(histogram[midpoint:(midpoint+quarter_point)]) + midpoint\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 15\n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 60\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 40\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Rectangle data for visualization\n",
    "    rectangle_data = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        rectangle_data.append((win_y_low, win_y_high, win_xleft_low, win_xleft_high, win_xright_low, win_xright_high))\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    left_fit, right_fit = (None, None)\n",
    "    # Fit a second order polynomial to each\n",
    "    if len(leftx) != 0:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    if len(rightx) != 0:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    visualization_data = (rectangle_data, histogram)\n",
    "    \n",
    "    return left_fit, right_fit, left_lane_inds, right_lane_inds, visualization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 0)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the result on example image\n",
    "exampleImg = mpimg.imread('./test_images/test2.jpg')\n",
    "exampleImg_bin, Minv = pipeline(exampleImg)\n",
    "    \n",
    "left_fit, right_fit, left_lane_inds, right_lane_inds, visualization_data = sliding_window(exampleImg_bin)\n",
    "\n",
    "h = exampleImg.shape[0]\n",
    "left_fit_x_int = left_fit[0]*h**2 + left_fit[1]*h + left_fit[2]\n",
    "right_fit_x_int = right_fit[0]*h**2 + right_fit[1]*h + right_fit[2]\n",
    "#print('fit x-intercepts:', left_fit_x_int, right_fit_x_int)\n",
    "\n",
    "rectangles = visualization_data[0]\n",
    "histogram = visualization_data[1]\n",
    "\n",
    "# Create an output image to draw on and  visualize the result\n",
    "out_img = np.uint8(np.dstack((exampleImg_bin, exampleImg_bin, exampleImg_bin))*255)\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, exampleImg_bin.shape[0]-1, exampleImg_bin.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "for rect in rectangles:\n",
    "# Draw the windows on the visualization image\n",
    "    cv2.rectangle(out_img,(rect[2],rect[0]),(rect[3],rect[1]),(0,255,0), 2) \n",
    "    cv2.rectangle(out_img,(rect[4],rect[0]),(rect[5],rect[1]),(0,255,0), 2) \n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "nonzero = exampleImg_bin.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [100, 200, 255]\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # Generate x and y values for plotting\\n    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\\n    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\\n    right_fitx = right_fit[0]*pltoy**2 + right_fit[1]*ploty +right_fit[2]\\n'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def polyfit_using_prev_fit(binary_warped, left_fit_prev, right_fit_prev):\n",
    "    # Assume you now have a new warped binary image\n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 60\n",
    "    left_lane_inds = ((nonzerox > (left_fit_prev[0]*(nonzeroy**2) + left_fit_prev[1]*nonzeroy + left_fit_prev[2] - margin)) & \n",
    "                      (nonzerox < (left_fit_prev[0]*(nonzeroy**2) + left_fit_prev[1]*nonzeroy + left_fit_prev[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit_prev[0]*(nonzeroy**2) + right_fit_prev[1]*nonzeroy + right_fit_prev[2] - margin)) & \n",
    "                       (nonzerox < (right_fit_prev[0]*(nonzeroy**2) + right_fit_prev[1]*nonzeroy + right_fit_prev[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    \"\"\"\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \"\"\"\n",
    "    left_fit_new, right_fit_new = (None, None)\n",
    "    if len(leftx) != 0:\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit_new = np.polyfit(lefty, leftx, 2)\n",
    "    if len(rightx) != 0:\n",
    "        right_fit_new = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "    return left_fit_new, right_fit_new, left_lane_inds, right_lane_inds\n",
    "\"\"\"\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*pltoy**2 + right_fit[1]*ploty +right_fit[2]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the result on example image\n",
    "exampleImg2 = mpimg.imread('./test_images/test5.jpg')\n",
    "exampleImg2_bin, Minv = pipeline(exampleImg2)   \n",
    "margin = 60\n",
    "left_fit2, right_fit2, left_lane_inds2, right_lane_inds2 = polyfit_using_prev_fit(exampleImg2_bin, left_fit, right_fit)\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, exampleImg2_bin.shape[0]-1, exampleImg2_bin.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "left_fitx2 = left_fit2[0]*ploty**2 + left_fit2[1]*ploty + left_fit2[2]\n",
    "right_fitx2 = right_fit2[0]*ploty**2 + right_fit2[1]*ploty + right_fit2[2]\n",
    "\n",
    "# Create an image to draw on and an image to show the selection window\n",
    "out_img = np.uint8(np.dstack((exampleImg2_bin, exampleImg2_bin, exampleImg2_bin))*255)\n",
    "window_img = np.zeros_like(out_img)\n",
    "\n",
    "# Color in left and right line pixels\n",
    "nonzero = exampleImg2_bin.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "out_img[nonzeroy[left_lane_inds2], nonzerox[left_lane_inds2]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds2], nonzerox[right_lane_inds2]] = [0, 0, 255]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area (OLD FIT)\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "plt.imshow(result)\n",
    "plt.plot(left_fitx2, ploty, color='yellow')\n",
    "plt.plot(right_fitx2, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Radius of curvature and distance from lane calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Method to determine radius of curvature and distance from lane center \n",
    "# based on binary image, polynomial fit, and L and R lane pixel indices\n",
    "def calc_curv_rad_and_center_dist(bin_img, l_fit, r_fit, l_lane_inds, r_lane_inds):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension, \n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension, \n",
    "    left_curverad, right_curverad, center_dist = (0, 0, 0)\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    h = bin_img.shape[0]\n",
    "    ploty = np.linspace(0, h-1, h)\n",
    "    y_eval = np.max(ploty)\n",
    "  \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = bin_img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[l_lane_inds]\n",
    "    lefty = nonzeroy[l_lane_inds] \n",
    "    rightx = nonzerox[r_lane_inds]\n",
    "    righty = nonzeroy[r_lane_inds]\n",
    "    \n",
    "    if len(leftx) != 0 and len(rightx) != 0:\n",
    "        # Fit new polynomials to x,y in world space\n",
    "        left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "        # Calculate the new radii of curvature\n",
    "        left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        # Now our radius of curvature is in meters\n",
    "    \n",
    "    # Distance from center is image x midpoint - mean of l_fit and r_fit intercepts \n",
    "    if r_fit is not None and l_fit is not None:\n",
    "        car_position = bin_img.shape[1]/2\n",
    "        l_fit_x_int = l_fit[0]*h**2 + l_fit[1]*h + l_fit[2]\n",
    "        r_fit_x_int = r_fit[0]*h**2 + r_fit[1]*h + r_fit[2]\n",
    "        lane_center_position = (r_fit_x_int + l_fit_x_int) /2\n",
    "        center_dist = (car_position - lane_center_position) * xm_per_pix\n",
    "    return left_curverad, right_curverad, center_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius of curvature for example: 1700.96501357 m, 4518.18464926 m\n",
      "Distance from lane center for example: -0.210503437043 m\n"
     ]
    }
   ],
   "source": [
    "rad_l, rad_r, d_center = calc_curv_rad_and_center_dist(exampleImg_bin, left_fit, right_fit, left_lane_inds, right_lane_inds)\n",
    "print('Radius of curvature for example:', rad_l, 'm,', rad_r, 'm')\n",
    "print('Distance from lane center for example:', d_center, 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_lane(original_img, binary_img, l_fit, r_fit, Minv):\n",
    "    new_img = np.copy(original_img)\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    ploty = np.linspace(0, h-1, num=h)# to cover same y-range as image\n",
    "    left_fitx = l_fit[0]*ploty**2 + l_fit[1]*ploty + l_fit[2]\n",
    "    right_fitx = r_fit[0]*ploty**2 + r_fit[1]*ploty + r_fit[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    cv2.polylines(color_warp, np.int32([pts_left]), isClosed=False, color=(255,0,0), thickness=15)\n",
    "    cv2.polylines(color_warp, np.int32([pts_right]), isClosed=False, color=(255,0,0), thickness=15)\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (binary_img.shape[1], binary_img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(new_img, 1, newwarp, 0.5, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f739d46c1d0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleImg_out1 = draw_lane(exampleImg, exampleImg_bin, left_fit, right_fit, Minv)\n",
    "plt.imshow(exampleImg_out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_data(original_img, curv_rad, center_dist):\n",
    "    new_img = np.copy(original_img)\n",
    "    h = new_img.shape[0]\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    text = 'Curve radius: ' + '{:04.2f}'.format(curv_rad) + 'm'\n",
    "    cv2.putText(new_img, text, (40,70), font, 1.5, (200,255,155), 2, cv2.LINE_AA)\n",
    "    direction = ''\n",
    "    if center_dist > 0:\n",
    "        direction = 'right'\n",
    "    elif center_dist < 0:\n",
    "        direction = 'left'\n",
    "    abs_center_dist = abs(center_dist)\n",
    "    text = '{:04.3f}'.format(abs_center_dist) + 'm ' + direction + ' of center'\n",
    "    cv2.putText(new_img, text, (40,120), font, 1.5, (200,255,155), 2, cv2.LINE_AA)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f73a4a68128>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleImg_out2 = draw_data(exampleImg_out1, (rad_l+rad_r)/2, d_center)\n",
    "plt.imshow(exampleImg_out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = []  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #number of detected pixels\n",
    "        self.px_count = None\n",
    "    def add_fit(self, fit, inds):\n",
    "        # add a found fit to the line, up to n\n",
    "        if fit is not None:\n",
    "            if self.best_fit is not None:\n",
    "                # if we have a best fit, see how this new fit compares\n",
    "                self.diffs = abs(fit-self.best_fit)\n",
    "            if (self.diffs[0] > 0.001 or \\\n",
    "               self.diffs[1] > 1.0 or \\\n",
    "               self.diffs[2] > 100.) and \\\n",
    "               len(self.current_fit) > 0:\n",
    "                # bad fit! abort! abort! ... well, unless there are no fits in the current_fit queue, then we'll take it\n",
    "                self.detected = False\n",
    "            else:\n",
    "                self.detected = True\n",
    "                self.px_count = np.count_nonzero(inds)\n",
    "                self.current_fit.append(fit)\n",
    "                if len(self.current_fit) > 5:\n",
    "                    # throw out old fits, keep newest n\n",
    "                    self.current_fit = self.current_fit[len(self.current_fit)-5:]\n",
    "                self.best_fit = np.average(self.current_fit, axis=0)\n",
    "        # or remove one from the history, if not found\n",
    "        else:\n",
    "            self.detected = False\n",
    "            if len(self.current_fit) > 0:\n",
    "                # throw out oldest fit\n",
    "                self.current_fit = self.current_fit[:len(self.current_fit)-1]\n",
    "            if len(self.current_fit) > 0:\n",
    "                # if there are still any fits in the queue, best_fit is their average\n",
    "                self.best_fit = np.average(self.current_fit, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    new_img = np.copy(img)\n",
    "    img_bin, Minv = pipeline(new_img)    \n",
    "    # if both left and right lines were detected last frame, use polyfit_using_prev_fit, otherwise use sliding window\n",
    "    if not l_line.detected or not r_line.detected:\n",
    "        l_fit, r_fit, l_lane_inds, r_lane_inds, _ = sliding_window(img_bin)\n",
    "    else:\n",
    "        l_fit, r_fit, l_lane_inds, r_lane_inds = polyfit_using_prev_fit(img_bin, l_line.best_fit, r_line.best_fit)      \n",
    "    # invalidate both fits if the difference in their x-intercepts isn't around 350 px (+/- 100 px)\n",
    "    if l_fit is not None and r_fit is not None:\n",
    "        # calculate x-intercept (bottom of image, x=image_height) for fits\n",
    "        h = img.shape[0]\n",
    "        l_fit_x_int = l_fit[0]*h**2 + l_fit[1]*h + l_fit[2]\n",
    "        r_fit_x_int = r_fit[0]*h**2 + r_fit[1]*h + r_fit[2]\n",
    "        x_int_diff = abs(r_fit_x_int-l_fit_x_int)\n",
    "        if abs(350 - x_int_diff) > 100:\n",
    "            l_fit = None\n",
    "            r_fit = None\n",
    "    l_line.add_fit(l_fit, l_lane_inds)\n",
    "    r_line.add_fit(r_fit, r_lane_inds)\n",
    "    # draw the current best fit if it exists\n",
    "    if l_line.best_fit is not None and r_line.best_fit is not None:\n",
    "        img_out1 = draw_lane(new_img, img_bin, l_line.best_fit, r_line.best_fit, Minv)\n",
    "        rad_l, rad_r, d_center = calc_curv_rad_and_center_dist(img_bin, l_line.best_fit, r_line.best_fit, \n",
    "                                                               l_lane_inds, r_lane_inds)\n",
    "        img_out = draw_data(img_out1, (rad_l+rad_r)/2, d_center)\n",
    "    else:\n",
    "        img_out = new_img\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Reference i looked into while solving the trouble shoot the lane lines\n",
    "https://github.com/jeremy-shannon/CarND-Advanced-Lane-Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [06:34<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "CPU times: user 23min 3s, sys: 2.53 s, total: 23min 5s\n",
      "Wall time: 6min 34s\n"
     ]
    }
   ],
   "source": [
    "l_line = Line()\n",
    "r_line = Line()\n",
    "video_output1 = 'project_video_output.mp4'\n",
    "video_input1 = VideoFileClip('project_video.mp4')\n",
    "processed_video = video_input1.fl_image(process_image)\n",
    "%time processed_video.write_videofile(video_output1, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Process Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challenge_video_output.mp4\n",
      "[MoviePy] Writing video challenge_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [02:25<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challenge_video_output.mp4 \n",
      "\n",
      "CPU times: user 8min 27s, sys: 1.24 s, total: 8min 29s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "l_line = Line()\n",
    "r_line = Line()\n",
    "video_output2 = 'challenge_video_output.mp4'\n",
    "video_input2 = VideoFileClip('challenge_video.mp4')\n",
    "processed_video = video_input2.fl_image(process_image)\n",
    "%time processed_video.write_videofile(video_output2, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"challenge_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Process Harder Challenge Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video harder_challenge_video_output.mp4\n",
      "[MoviePy] Writing video harder_challenge_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [06:18<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: harder_challenge_video_output.mp4 \n",
      "\n",
      "CPU times: user 22min 6s, sys: 2.42 s, total: 22min 9s\n",
      "Wall time: 6min 18s\n"
     ]
    }
   ],
   "source": [
    "l_line = Line()\n",
    "r_line = Line()\n",
    "video_output3 = 'harder_challenge_video_output.mp4'\n",
    "video_input3 = VideoFileClip('harder_challenge_video.mp4')#.subclip(0,3)\n",
    "#video_input3.save_frame(\"hard_challenge01.jpeg\") # saves the first frame\n",
    "processed_video = video_input3.fl_image(process_image)\n",
    "%time processed_video.write_videofile(video_output3, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"harder_challenge_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob('challenge/output*.jpg')\n",
    "for image in images:\n",
    "    img = mpimg.imread(image)    \n",
    "    # Test undistortion on image\n",
    "    combination, Minv = pipeline(img)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(combination,cmap='gray')\n",
    "    ax2.set_title('correction', fontsize=30)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ffmpeg -i challenge_video.mp4 -r 0.25 output%1d.png I used the following command for generating images. As you can see i am unable to second lane in challenger video.Please let me know how to address this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob('harder/output*.jpg')\n",
    "for image in images:\n",
    "    img = mpimg.imread(image)    \n",
    "    # Test undistortion on image\n",
    "    combination, Minv = pipeline(img)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(combination,cmap='gray')\n",
    "    ax2.set_title('correction', fontsize=30)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My pipeline is not robust for this challenge. I have to try and learn computational geometry and color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "01a359767b434eea8cdcd85a0240e060": {
     "views": []
    },
    "03a653a4b5b244dabee9dc917a32ee4e": {
     "views": []
    },
    "0500d705e98e44798324890b73750b87": {
     "views": []
    },
    "0539b76b5c0347859a7322887e7c255c": {
     "views": []
    },
    "055f97ad491a43cdbec54612eb78f7cf": {
     "views": []
    },
    "05a87be8c53d453186e09a84075d7d89": {
     "views": []
    },
    "060daafa01d249b1b5692758113ca2cf": {
     "views": []
    },
    "0670dcd7fba8480f8d9a0c2da56fbf0d": {
     "views": []
    },
    "07ca6d018d334737bf8a24dc0578bd8d": {
     "views": []
    },
    "08b61d9415cb483688a1fe8c4ebab42a": {
     "views": []
    },
    "08bb7a37c9ce43cc889db4b8feddc4c7": {
     "views": []
    },
    "09a54d35befe403aac33d3ae99dae491": {
     "views": []
    },
    "0bd794d549ff4337baec4225a29680ca": {
     "views": []
    },
    "0d533528e20840179540df65a7831cf1": {
     "views": []
    },
    "0f9f7117bfa14f9c8ea6d3843ec356ae": {
     "views": []
    },
    "1056fcba87274b10b031079cf062ac46": {
     "views": []
    },
    "1104b6beef684c83823c833b3a1b745d": {
     "views": []
    },
    "1159b2f416404afea415cfac894e70d0": {
     "views": []
    },
    "129dcb4a22ff4a269ed4b0c5ab9dd0be": {
     "views": []
    },
    "12a36657c56245f0813533721743dd10": {
     "views": []
    },
    "1372092d6823441aaf6c6fed713a8acc": {
     "views": []
    },
    "13e3ee5571ff4f0e8cf70dbb84f49a33": {
     "views": []
    },
    "1426048737c6456d88c634562387fe90": {
     "views": []
    },
    "14df8a05894f4c3f9cc6087c69d7ac65": {
     "views": []
    },
    "15f8a6ad17174dc198c532196d3761f8": {
     "views": []
    },
    "16f35e2d56ff49c280b765be4fe40fa6": {
     "views": []
    },
    "1707419d8e7e4959aea1630871400f92": {
     "views": []
    },
    "1732d4a963c34cd3ae65c8e559bc49fb": {
     "views": []
    },
    "1768c1df88084e609a28e0ec2227ae63": {
     "views": []
    },
    "19b4c647eb3c4ba5bd7920051af51782": {
     "views": []
    },
    "1bd115f61984474c919c70ae129e1a3c": {
     "views": []
    },
    "1be46b357f554f11ac4ee2b137cfed70": {
     "views": []
    },
    "1bf81cb5aa1d44a686b8b4e9cec900fb": {
     "views": []
    },
    "1c655efd95a94b13bf8682d0e2300a87": {
     "views": []
    },
    "1dbdb9a418d44a4aa4178131fc4651ef": {
     "views": []
    },
    "201bbc779a7b4a6492ff6e4e33787451": {
     "views": []
    },
    "2109b5f25cd14efd945b6d34f95dfcad": {
     "views": []
    },
    "21474b58a841481bad8bb408a01a16ef": {
     "views": []
    },
    "215b9cba76264bb5a305e1c7f1473977": {
     "views": []
    },
    "217f3b3f005b4614a40a83fb989fd543": {
     "views": []
    },
    "226a8708a4104e98afbd3f7afd0e5767": {
     "views": []
    },
    "2393e2ae602e4a2689c235d880890697": {
     "views": []
    },
    "248be3d0d2794ae887329b6b9ed94369": {
     "views": []
    },
    "25c9f097ae80480a892f47173eebf33a": {
     "views": []
    },
    "27dccb80a60d4f5b989449431861943c": {
     "views": []
    },
    "27eb2e7b0392476db758a6855b450065": {
     "views": []
    },
    "28e6e5cbf5184a00b7c713a20ebb6aea": {
     "views": []
    },
    "29f6508656a34a6b81e978e407f03da1": {
     "views": []
    },
    "2a00bacac6fa4cf9a02efd6014c38b36": {
     "views": []
    },
    "2a30f033e3c946ddb1b73879309d5082": {
     "views": []
    },
    "2b97d044e62b4c67a000045e7b11c7d4": {
     "views": []
    },
    "2bdc4d1332fa421db0c730ee9b32b845": {
     "views": []
    },
    "2cb938d2f90b4de68fd9e28dcb818ce4": {
     "views": []
    },
    "2e359aa644f84d619847391460982456": {
     "views": []
    },
    "2eb3328b11d8433fb7856de3079fa34f": {
     "views": []
    },
    "2ef2841017e6410c9b18c8cdcf3616d2": {
     "views": []
    },
    "2f76086c8bbd4a7d834b11beb485c954": {
     "views": []
    },
    "2fd72241cabb4cef9d7f8ff6db8944c7": {
     "views": []
    },
    "302ca731b16a46ffac3c253ee7cfc58c": {
     "views": []
    },
    "32e52d8787b546a297bd608f86bc59fc": {
     "views": []
    },
    "3354072fc6a442c7ad53f69bd321572c": {
     "views": []
    },
    "33f609727fe24fd299919a6a7a53c383": {
     "views": []
    },
    "344e29b31b3f4ceca4725ada5364f3f0": {
     "views": []
    },
    "35cf7750074a454a82eaf6f0b995291b": {
     "views": []
    },
    "38bff26a360f4dc29830c9590fb63328": {
     "views": []
    },
    "3bb87b26a3cd4edebbf27ba2689fc278": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "3cffd8e180e342ad814ac727ce38e690": {
     "views": []
    },
    "3dc410a574af4940ac9a5281846413eb": {
     "views": []
    },
    "3e109df2b8864dde8ba4334607bf6f2d": {
     "views": []
    },
    "3e7deefbcb054b4e982cd412a15eb082": {
     "views": []
    },
    "3f5244f273bd4f86b3d9d83334772331": {
     "views": []
    },
    "3fcee64852a343f7b4cf6a5e4bd2151c": {
     "views": []
    },
    "4009ffbada0346f1b09df42fa1f38839": {
     "views": []
    },
    "401c4b25cf504d768b772830b9c28eae": {
     "views": []
    },
    "41e101bd27964866b4ab5b0a77678f9d": {
     "views": []
    },
    "425fe7a4b60b40c3853823a82f52185a": {
     "views": []
    },
    "42a5371829d04a4db62ecf46bc7d784d": {
     "views": []
    },
    "42d06e3962b44240b157f22825689af1": {
     "views": []
    },
    "4468c0a7e41e44c0894519fc368b0807": {
     "views": []
    },
    "452484108b6c4dc7bd98538a20e59688": {
     "views": []
    },
    "45baecb5634c4c1aba702e930a338a85": {
     "views": []
    },
    "467e3001c0b24751951e6d4e79106f33": {
     "views": []
    },
    "46dd74064a5a47b6a81edb1f8506a275": {
     "views": []
    },
    "489bfa57adbf4efc82b4650dd14cc70c": {
     "views": []
    },
    "4a57dbf46cb7497382018978d50ef007": {
     "views": []
    },
    "4bb61219213b4b80bcfe43ebd0b98861": {
     "views": []
    },
    "4cac79a746c94a72a83b81df9757c51a": {
     "views": []
    },
    "4e0879ff948a473c95defe5493bce5eb": {
     "views": []
    },
    "4f43bcf3e9ce4897b97d19fdfbe917a6": {
     "views": []
    },
    "52dac7db3dbc464bb9c386ffd515aa4a": {
     "views": []
    },
    "52eeff82bd614119a1743834e6725be2": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "5310c74061dc4d7488f2c73bd4dad2a3": {
     "views": []
    },
    "56508d4ca5e04a98be6cb566d4b512c4": {
     "views": []
    },
    "566d573aec2c460490769107cd58d747": {
     "views": []
    },
    "576d6da7676a4c178a6543ee80be9848": {
     "views": []
    },
    "5876a6c36690435b99d859abbc4b7346": {
     "views": []
    },
    "5ba22f58acc343679a65635156bc70eb": {
     "views": []
    },
    "5be9f7aae309451399caad560c9d0a44": {
     "views": []
    },
    "5d03cdad30134f3a9df1f798eb92419e": {
     "views": []
    },
    "5df239802a7a40f0870ce8f159f3ac06": {
     "views": []
    },
    "5ef55fb400814f4fbc6cc9aea0a28dbd": {
     "views": []
    },
    "5f89e987eda54e4d9994210c073b1402": {
     "views": []
    },
    "5fcca5d3c6884f07b2ac8670a6feb727": {
     "views": []
    },
    "5fea17b1f21a40cda9ed63b4a0651c72": {
     "views": []
    },
    "601b42e1081a407ca386160a4073d488": {
     "views": []
    },
    "60ee625fba8d4303bd9e333f0334b6d0": {
     "views": []
    },
    "6119df6447eb4733a4c68039865fdbb4": {
     "views": []
    },
    "626d4c44b74b4ab1b52d907396447d3d": {
     "views": []
    },
    "62ea3320be9643309f86b3e34df3402b": {
     "views": []
    },
    "64281a19ca0e4930b5c0a5950f00576c": {
     "views": []
    },
    "659b2eca39734cc49319d82d6956212f": {
     "views": []
    },
    "6678a0b42e5d43e1a0f62e4468b0f1da": {
     "views": []
    },
    "67df69c79e9740b890d1016c96299907": {
     "views": []
    },
    "680712f2ec3845e3a722a3feea64a8d0": {
     "views": []
    },
    "68a258198ba0431caf51fb72a5ed1cdc": {
     "views": []
    },
    "6a66dfaabdfc41aeab11722e39501c8b": {
     "views": []
    },
    "6a71b619fa1e4f3ba4eae1e6742537b7": {
     "views": []
    },
    "6a9ff18f67b14618856446e542bb6497": {
     "views": []
    },
    "6bb4d182ed8242598123fed76b8ad641": {
     "views": []
    },
    "6da4c1086a14493a99e2e43eb6e3f3f0": {
     "views": []
    },
    "6e27cf4b29ac414fa225341baad9dc54": {
     "views": []
    },
    "6fa21ddf392641e9a9592dda4881278e": {
     "views": []
    },
    "70b1635b89d249c2aae2e1272b528641": {
     "views": []
    },
    "71745d92e3704c8ebc55082b7c0c3e32": {
     "views": []
    },
    "7194e147568544a48a8aa7d31eb9b1c2": {
     "views": []
    },
    "72555e7471764aa2ab0c0f05290ecfd8": {
     "views": []
    },
    "7281cc654f9e46b48fa4b2556f6ed692": {
     "views": []
    },
    "734b58570a744cd0b0eec4db32aada6d": {
     "views": []
    },
    "7537747091b64b95afc58b52004c3ea2": {
     "views": []
    },
    "77ed5cfe8a6547e8bfcb904c0ab13a8d": {
     "views": []
    },
    "783fbad6c34444e291a20da97985acf0": {
     "views": []
    },
    "78b50c108c0d4ac3822d8744d95e2ee1": {
     "views": []
    },
    "7a30942f51a249d1834d392c267b279f": {
     "views": []
    },
    "7b6a2e8d3bd142f998efbe857e18739b": {
     "views": []
    },
    "7d5040aabc9c4125b6af4e895a2ab395": {
     "views": []
    },
    "7fbb6ea2afb84196b1c48943cf81a39a": {
     "views": []
    },
    "7fdfe5795e9f4be787d99a86deebbe49": {
     "views": []
    },
    "8023d743a491449ab6c5383f0d1fdd8d": {
     "views": []
    },
    "83874286e9514f22a746166f7448b866": {
     "views": []
    },
    "8428e573946741d1b3334661aed2917b": {
     "views": []
    },
    "84e5a99b9e9b4eeb9a1d9210324b18b6": {
     "views": []
    },
    "8539ee2019db4161a53ecf8647d8b8b8": {
     "views": []
    },
    "854c3f92bcfa4b24960b9ac5cf92babb": {
     "views": []
    },
    "88f6b348cc76485f949c0be56ea10043": {
     "views": []
    },
    "893523b96e4f4e928072b0cfcac165d4": {
     "views": []
    },
    "893749b2315a43ee86e850d7bf7826b7": {
     "views": []
    },
    "8a961ea09dac4d5881f6d0d5f3cbbd78": {
     "views": []
    },
    "8b2c79311753485d9348ff59718410ac": {
     "views": []
    },
    "8bc6b8218e014a16ad20821cee9b6d94": {
     "views": []
    },
    "8e3ece84e2854200bc7c081fff3ff462": {
     "views": []
    },
    "8e9c3d173a6145689dd32c3b7d5db5c7": {
     "views": []
    },
    "8edc545337ed42b1b942689c9f868230": {
     "views": []
    },
    "8fb5f486a4e64e51b61823a06bb23c14": {
     "views": []
    },
    "90ebf781de224d14a27eee8eba67a343": {
     "views": []
    },
    "913e13c42cf84d35ab96a4ee2202f7af": {
     "views": []
    },
    "915e8417b6474167a05c4b44133900d1": {
     "views": []
    },
    "91fa40cbd10e450cbf2218688bc0ae1f": {
     "views": []
    },
    "92df7f46d90d4f87b26455c1a4eb624d": {
     "views": []
    },
    "93bb2bc4266f498baf0aa7feeaaa0f9e": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "957f3e0d4c9748d48b6ffc9753ced742": {
     "views": []
    },
    "968fe1f180c44f439baf13c7b670d135": {
     "views": []
    },
    "971de4e8109d4421aad976a32dd27ec9": {
     "views": []
    },
    "99261b2062ec498d8b784b8ead833f47": {
     "views": []
    },
    "993137e28ed9411db2467fc4f52bd3d5": {
     "views": []
    },
    "99aa50781d5e4ea99ff3d91a3962e2a2": {
     "views": []
    },
    "9c9b734300354d26a8f5fbcb21f92d33": {
     "views": []
    },
    "9cdb8acc2a774b6bb21a3c8b01ba0195": {
     "views": []
    },
    "9dac37a57b4842d2923514b9efcd06ae": {
     "views": []
    },
    "a14834c7ce824362ab275a367e5f1c72": {
     "views": []
    },
    "a153099ec9284ed9849931b363f28956": {
     "views": []
    },
    "a2a8ae15a59d4fad8892b9e4cf7c629f": {
     "views": []
    },
    "a37de6c4c2c04bbfba57ea97f38fb857": {
     "views": []
    },
    "a3b92782f5b3459ebe081d31edfd3f7f": {
     "views": []
    },
    "a4b16401470f48a283588ba56000ed27": {
     "views": []
    },
    "a5f01516dee54f618a2b773bae637963": {
     "views": []
    },
    "a61a6f1b61fe444bab934f35f688f039": {
     "views": []
    },
    "a61e88c3ef854966909076496782ed1f": {
     "views": []
    },
    "a67a5364faba465181a9c69bd92e95c3": {
     "views": []
    },
    "a69898c5d0934bdf8268e5de6768c504": {
     "views": []
    },
    "a6ffc0da944f49ddbfc9fcab36677788": {
     "views": []
    },
    "a9fdc1afa916479aa04f4cf80e1cf713": {
     "views": []
    },
    "ab41b6facf1e49d287b49ec209d40a45": {
     "views": []
    },
    "ab5e9a95e93e4f81bfe3af26475cc053": {
     "views": []
    },
    "ad2ae20c59994cbaa9feee49301d2dac": {
     "views": []
    },
    "ad51ffb5d5cc49e29299cc9c939d51db": {
     "views": []
    },
    "ada2397e713b4fd8bb2cdd9ef9d1f249": {
     "views": []
    },
    "ae2ad8b08e554873ad770dd701f85598": {
     "views": []
    },
    "aec1a0acce4246929916d70a7c5f9cc0": {
     "views": []
    },
    "af51e46a19fc43f89ab4a7cdd85769e9": {
     "views": []
    },
    "b02c709d41e24a4f94c44f93972771ce": {
     "views": []
    },
    "b0681da670404566a95759002a1850a3": {
     "views": []
    },
    "b0d775ff3c1c4ea3bea608fe2e92431d": {
     "views": []
    },
    "b353ecf5fb9d40fe9ac028bb466e7464": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "b4e6cbe9742a4dc780d6f68621bb44de": {
     "views": []
    },
    "b55aec032c30485e90db68b382827f1d": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "b5a5e48098874bab8e1ce4b8679e0a34": {
     "views": []
    },
    "b61ecb62c30441c9ab9865a8a31f0a68": {
     "views": []
    },
    "b71f935433b04249a89833a4d06cac08": {
     "views": []
    },
    "b81e6568b7d64833b916a6069a53463f": {
     "views": []
    },
    "b8a5067e62e24a1aba2c00364a429fdf": {
     "views": []
    },
    "b93a52c97f384ae4b0e60c705506c5a7": {
     "views": []
    },
    "b99b87ee63cb4dfdaf415b6f4ba4bfde": {
     "views": []
    },
    "ba20ba570cc848a1b1b911b70615193f": {
     "views": []
    },
    "bb17dc8203d8451aabe90ed075756fea": {
     "views": []
    },
    "bc02f94adcd744a6b9798bfb76fa14bc": {
     "views": []
    },
    "bc350780cedf40abbdd0e18e4f94a410": {
     "views": []
    },
    "bc738273be43477fa27f592b4805a672": {
     "views": []
    },
    "bd436f50b8a8459a8d398cee2f88ff86": {
     "views": []
    },
    "bf2e614eb94749928323491b60ab1333": {
     "views": []
    },
    "bfcb20b3361f4170ac5ed19c9edc845f": {
     "views": []
    },
    "c27bd2175728480cbf1b869ff8039acd": {
     "views": []
    },
    "c368a4fb25304a8e94716653731aa7df": {
     "views": []
    },
    "c5036bbb892c49b6b60c857c956872cb": {
     "views": []
    },
    "c568dee322924080a50191f73f4ba216": {
     "views": []
    },
    "c7c05e5f77cf4513bf0bc6328e59a4b3": {
     "views": []
    },
    "c88005a7f5434f269fcd526181913140": {
     "views": []
    },
    "c95bf0a75b0b48e3846da4401cd6a8f8": {
     "views": []
    },
    "c98771bc6db744cfbe84692a802a45f5": {
     "views": []
    },
    "ca3833c7632a436588a21a0b9718d478": {
     "views": []
    },
    "cafdc173e6c54d28bf2e63bcd61ba4b2": {
     "views": []
    },
    "cb2a45e59d6e4f9ab13fe39b78f4b435": {
     "views": []
    },
    "cb58787d32fa4c759e7bbeb2eec84041": {
     "views": []
    },
    "cb8534987a2f4d59910773ae5d6ab3f8": {
     "views": []
    },
    "cc5c2f3e535c46749b25653563f3ff7c": {
     "views": []
    },
    "cc9eeced4bc44fcab26c456c5dad073e": {
     "views": []
    },
    "ccd2f4ed8e824b81bcd7b3ab40d42c70": {
     "views": []
    },
    "cd0f10456cad4f5a85f80b717d80bdfe": {
     "views": []
    },
    "cf3607f1666b4c09b601b424a2b21921": {
     "views": []
    },
    "cfaea79e00f64be5ad291feb82cbb1e0": {
     "views": []
    },
    "cfdf88f65ab74affb2cbd3f658b978d0": {
     "views": []
    },
    "d0c3756db4894828b6ff725e30dc0edb": {
     "views": []
    },
    "d2cab73f57b84df18e4a8492a4b4b4bb": {
     "views": []
    },
    "d2edb40f5a8b47b5867b4d548e0a5988": {
     "views": []
    },
    "d34fd37a286a461d81e620d1c091b7f7": {
     "views": []
    },
    "d4dd1d67e3cb4ad28cabf21a2d6785fe": {
     "views": []
    },
    "d5353d28c7844b0d9379022d96bab820": {
     "views": []
    },
    "d67a57eca67648e1899bdd9086fe6fef": {
     "views": []
    },
    "d6b36a3b668c4d15828d433f20cb6287": {
     "views": []
    },
    "d6c94a8473c84b949d7c79d4eff89c62": {
     "views": []
    },
    "d6d7d6cb3eea4164a6b4ba0db7d4284d": {
     "views": []
    },
    "d7be6af25588489ab981c571ed620c77": {
     "views": []
    },
    "d997b86976754822b4dd9ea8f2ac0dae": {
     "views": []
    },
    "da5c7b222a0b40f7833fa31b408d3906": {
     "views": []
    },
    "dabf47417b154e2ab0c81fe94ec7ed4c": {
     "views": []
    },
    "db437a6fef0444c19c0215f66244a192": {
     "views": []
    },
    "dc200889fc2448b9bdbe77d611fdb96f": {
     "views": []
    },
    "dd7ede66af384c249194ec6c7c3b774c": {
     "views": []
    },
    "dd82b4c744b64cecbf21e0db45bf4986": {
     "views": []
    },
    "ddeea7e92d994f67bb8fd37e2e7d35ca": {
     "views": []
    },
    "df1cca179ea140afae90fe0ec430eb58": {
     "views": []
    },
    "dfd1b2e5077f46e881e5bacf586c7a86": {
     "views": []
    },
    "e0c6601157b444a18a94bf4e70f77128": {
     "views": []
    },
    "e0cb15c693904e238654df79c7ffda57": {
     "views": []
    },
    "e3e29823a87a419fb45b3aca018e3c68": {
     "views": []
    },
    "e3e891b74eb448ffbaef33fb88ab2668": {
     "views": []
    },
    "e434924e27dd41a3a84c695fc581f4fe": {
     "views": []
    },
    "e546b4408703424abb3607ee72febdbf": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "e566224215fd444fb9b643afa4a7c5d1": {
     "views": []
    },
    "e890714486e84e948c60a8a155a35645": {
     "views": []
    },
    "e8fe97c2d12b47dd8480752604f0844f": {
     "views": []
    },
    "ea88519cccc7499eafc992400d0eeee0": {
     "views": []
    },
    "eaaaafcc6b224a8f8a764d146bad72c6": {
     "views": []
    },
    "eb10ea35d53e4025abcb5619cb8d0591": {
     "views": []
    },
    "efd2c19ed7ee47c1979838e7e00655b9": {
     "views": []
    },
    "efe7920450e145efbc9392d356b1199e": {
     "views": []
    },
    "f20a22dc7cba46e09e1821a973a44372": {
     "views": []
    },
    "f20d4aeb803849a7bae59da011fd0c97": {
     "views": []
    },
    "f5ac4b4e262e4f44a42845ec7d8e689e": {
     "views": []
    },
    "f67fd54477174c5492f910560a3ee155": {
     "views": []
    },
    "f785c7e44628416cb2aac7ea18ab09bd": {
     "views": []
    },
    "f97bbe70759f4232a13c6f123bd9e294": {
     "views": []
    },
    "fb19d743ad084175bfa97fd6e6bf6b7a": {
     "views": []
    },
    "fb29de8e244548ab989d904bac583f61": {
     "views": []
    },
    "fe17037049c843c98341c2fd940541aa": {
     "views": []
    },
    "ff0d485ba1e24cb98e881bd185d54227": {
     "views": []
    },
    "ff9bd6e40155446a94f6d1033d428b0b": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
