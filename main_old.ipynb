{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The goals/steps of this project are the following:\n",
    ". Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    ". Apply a distortion correction to raw images.\n",
    ". Use color transforms, gradients, etc., to create a threshold binary image.\n",
    ". Detect lane pixels and fit to find the lane boundary\n",
    ". Determine the curvature of the lane and vehicle position with respect to center.\n",
    ". Warp the detected lane boundaries back onto the original image.\n",
    ". Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import glob\n",
    "import pickle\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display \n",
    "from IPython.display import Image\n",
    "from ipywidgets import interactive, interact, fixed\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "%matplotlib qt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Calibrating camera\n",
    "Steps involved in camera calibration:\n",
    "i. Arrays to store object pointsand image points from all the images\n",
    "ii. convert to grayscale\n",
    "iii. Find chess board corners\n",
    "iv. If corners are found add image points and object points\n",
    "\"\"\"\n",
    "def camera_calibration(images, nx, ny):\n",
    "    # Arrays to store object points and image points\n",
    "    objpoints = [] # 3D points in real world space\n",
    "    imgpoints = [] # 2D points i image plane\n",
    "    # Prepare object points by creating 9X6 points in  array each with 3 columns for the x,y,z coordinates of each corner\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    # Use numpy mgrid function to generate the coordinates \n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "    \n",
    "    for image in images:\n",
    "        img = mpimg.imread(image)\n",
    "        \n",
    "        # convert image to grayscale\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "        #print(ret)\n",
    "        # If corners are found, add image points and object points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            # draw and display the corners\n",
    "            # img = cv2.drawChessboardCorners(img, (nx,ny),corners, ret)\n",
    "            # plt.imshow(img)\n",
    "            \n",
    "    return cv2.calibrateCamera(objpoints, imgpoints, img.shape[0:2], None, None)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx = 9\n",
    "ny = 6\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "#Checking file directory\n",
    "#img = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "#plt.figure()\n",
    "#plt.imshow(img)\n",
    "#calibrate the camera\n",
    "ret, mtx,dist, rvecs, tvecs = camera_calibration(images,nx,ny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global mtx,dist,nx,ny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Correcting the distortion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camera_undistort(img, mtx, dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform distortion correction on one camera calibration image\n",
    "img = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "# Test undistortion on image\n",
    "dst = camera_undistort(img, mtx, dist)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Correcting the distortion', fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform distortion correction on test images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "for image in images:\n",
    "    img = mpimg.imread(image)    \n",
    "    # Test undistortion on image\n",
    "    dst = camera_undistort(img, mtx, dist)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('correcting the distortion', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image, number of x and y points, \n",
    "# camera matrix and distortion coefficients\n",
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Convert undistorted image to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    # Search for corners in the grayscaled image\n",
    "    # ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    # global warped\n",
    "    # if ret == True:\n",
    "    # If we found corners, draw them! (just for fun)\n",
    "    h,w = gray.shape\n",
    "    # cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "    # Choose offset from image corners to plot detected corners\n",
    "    # This should be chosen to present the result at the proper aspect ratio\n",
    "    # For source points I'm grabbing the outer four detected corners\n",
    "    src = np.float32([[575,464],[707,464],[258,682],[1049,682]])\n",
    "    # For destination points, I'm arbitrarily choosing some points to be\n",
    "    # a nice fit for displaying our warped result \n",
    "    # again, not exact, but close enough for our purposes\n",
    "    dst = np.float32([[450,0],[w-450,0],[450,h],[w-450,h]])\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    return cv2.warpPerspective(undist, M, gray.shape[::-1], flags = cv2.INTER_LINEAR), M, Minv\n",
    "\n",
    "# Return the resulting image and matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform distortion correction on one camera calibration image\n",
    "img = mpimg.imread('test_images/test3.jpg')\n",
    "# Test the corners_unwarp on test image\n",
    "unwarp_img, M, Minv = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "# Minv is used at the end for projecting the path onto real world\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(unwarp_img)\n",
    "ax2.set_title('Unwarped_Image', fontsize=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "# Note: calling your function with orient='x', thresh_min=5, thresh_max=100\n",
    "# should produce output like the example image shown above this quiz.\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=25, thresh_max=210):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    # binary_output = np.copy(img) # Remove this line\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def debug(min_thresh, max_thresh):\n",
    "    # Run the function\n",
    "    grad_binary = abs_sobel_thresh(unwarp_img, orient='x', thresh_min=min_thresh, thresh_max=max_thresh)\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(unwarp_img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(grad_binary, cmap='gray')\n",
    "    ax2.set_title('Thresholded Gradient', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "interact(debug, min_thresh=(0,255), max_thresh=(0,255))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# threshold levels set as (25,210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=9, mag_thresh_min=30, mag_thresh_max = 100):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Calculate the magnitude \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "     # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh_min) & (gradmag <= mag_thresh_max)] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def debug(kernel_size, min_thresh, max_thresh):\n",
    "    # Run the function\n",
    "    mag_binary = mag_thresh(unwarp_img, sobel_kernel=kernel_size, mag_thresh_min = min_thresh, mag_thresh_max = max_thresh)\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(unwarp_img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(mag_binary, cmap='gray')\n",
    "    ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "interact(debug, kernel_size=(1,11,2), min_thresh=(0,255),max_thresh=(0,255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kernel size = 9, thresh=(30,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function that applies Sobel x and y, \n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(img, sobel_kernel=15, thresh_min=0.70, thresh_max = 1.30):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    # binary_output = np.copy(img) # Remove this line\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh_min) & (absgraddir <= thresh_max)] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def debug(kernel_size, min_thresh, max_thresh):\n",
    "    # Run the function\n",
    "    dir_binary = dir_threshold(unwarp_img, sobel_kernel=kernel_size, thresh_min=min_thresh, thresh_max = max_thresh)\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(unwarp_img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(dir_binary, cmap='gray')\n",
    "    ax2.set_title('Thresholded Grad. Dir.', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "interact(debug, kernel_size=(1,21,2),min_thresh=(0,np.pi/2,0.01),max_thresh=(0,np.pi/2,0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kernel_size = 15, threshold=(0.7,1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hls_channel(img, channel_index = 2, thresh_min = 90,thresh_max = 255):\n",
    "    # Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    # Extract the desired channel\n",
    "    channel = hls[:,:,channel_index]\n",
    "    \n",
    "    # Apply the threshold\n",
    "    binary_s = np.zeros_like(channel)\n",
    "    binary_s[(channel>=thresh_min)&(channel<=thresh_max)]=1\n",
    "    return binary_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def debug(name_channel, min_thresh, max_thresh):\n",
    "    binary_s = hls_channel(unwarp_img, channel_index = name_channel, thresh_min = min_thresh, thresh_max = max_thresh)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(unwarp_img,cmap = 'gray')\n",
    "    ax1.set_title('test Image', fontsize=30)\n",
    "    ax2.imshow(binary_s,cmap = 'gray')\n",
    "    ax2.set_title(str(name_channel)+'channel of hls Binary Image', fontsize=30)\n",
    "    \n",
    "interact(debug,name_channel=(0,2,1), min_thresh = (0,255),max_thresh = (0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# currently using only s channel as mentioned by instructor threshold = (90,255).\n",
    "# I am also using H channel thresh=(15,106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "\"\"\"\n",
    "Functions\n",
    "i. camera_undistort(img, mtx, dist)\n",
    "ii.corners_unwarp(img, nx, ny, mtx, dist)\n",
    "iii. abs_sobel_thresh(img, orient='x', thresh_min=25, thresh_max=210\n",
    "iv.mag_thresh(img, sobel_kernel=9, mag_thresh_min=30, mag_thresh_max = 100)\n",
    "v. dir_threshold(img, sobel_kernel=15, thresh_min=0.70, thresh_max = 1.30)\n",
    "vi. hls_channel(img, channel_index = 2, thresh_min = 90,thresh_max = 255)\n",
    "\"\"\"\n",
    "def pipeline(image):\n",
    "    img = camera_undistort(image,mtx,dist)\n",
    "    unwarp_img, M, Minv = corners_unwarp(img,nx,ny,mtx,dist)\n",
    "    s_channel = hls_channel(unwarp_img)\n",
    "    h_channel = hls_channel(unwarp_img,channel_index = 0, thresh_min = 25, thresh_max = 90)\n",
    "    sobelAbs = abs_sobel_thresh(unwarp_img)\n",
    "    sobelMag = mag_thresh(unwarp_img)\n",
    "    sobelDir = dir_threshold(unwarp_img)\n",
    "    combo = np.zeros_like(sobelAbs)\n",
    "    combo[((s_channel==1)|(h_channel==1))|((sobelAbs==1)|(sobelMag==1))]=1\n",
    "          #|(sobelDir==1)]=1\n",
    "    return combo, Minv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform the combination of all features on test images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "for image in images:\n",
    "    img = mpimg.imread(image)    \n",
    "    # Test undistortion on image\n",
    "    combination, Minv = pipeline(img)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(combination,cmap='gray')\n",
    "    ax2.set_title('correction', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test3.jpg')\n",
    "combination, Minv = pipeline(image)\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.figure()\n",
    "plt.imshow(combination,cmap='gray')\n",
    "plt.figure()\n",
    "histogram = np.sum(combination[combination.shape[0]/2:,:], axis=0)\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binary_warped = combination\n",
    "# Create an output image to draw on and  visualize the result\n",
    "out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "# Find the peak of the left and right halves of the histogram\n",
    "# These will be the starting point for the left and right lines\n",
    "midpoint = np.int(histogram.shape[0]/2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set height of windows\n",
    "window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "nonzero = binary_warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "# Current positions to be updated for each window\n",
    "leftx_current = leftx_base\n",
    "rightx_current = rightx_base\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "left_lane_inds = []\n",
    "right_lane_inds = []\n",
    "\n",
    "# Step through the windows one by one\n",
    "for window in range(nwindows):\n",
    "    # Identify window boundaries in x and y (and right and left)\n",
    "    win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "    win_y_high = binary_warped.shape[0] - window*window_height\n",
    "    win_xleft_low = leftx_current - margin\n",
    "    win_xleft_high = leftx_current + margin\n",
    "    win_xright_low = rightx_current - margin\n",
    "    win_xright_high = rightx_current + margin\n",
    "    # Draw the windows on the visualization image\n",
    "    cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "    cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "    # Identify the nonzero pixels in x and y within the window\n",
    "    good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "    good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "    # Append these indices to the lists\n",
    "    left_lane_inds.append(good_left_inds)\n",
    "    right_lane_inds.append(good_right_inds)\n",
    "    # If you found > minpix pixels, recenter next window on their mean position\n",
    "    if len(good_left_inds) > minpix:\n",
    "        leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "    if len(good_right_inds) > minpix:        \n",
    "        rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "# Concatenate the arrays of indices\n",
    "left_lane_inds = np.concatenate(left_lane_inds)\n",
    "right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "# Extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Measuring curvature\n",
    "# Generate some fake data to represent lane-line pixels\n",
    "ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "quadratic_coeff = 3e-4 # arbitrary quadratic coefficient\n",
    "# For each y position generate random x position within +/-50 pix\n",
    "# of the line base position in each case (x=200 for left, and x=900 for right)\n",
    "leftx = np.array([200 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                              for y in ploty])\n",
    "rightx = np.array([900 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                                for y in ploty])\n",
    "\n",
    "leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "\n",
    "\n",
    "# Fit a second order polynomial to pixel positions in each fake lane line\n",
    "left_fit = np.polyfit(ploty, leftx, 2)\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fit = np.polyfit(ploty, rightx, 2)\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "# Plot up the fake data\n",
    "mark_size = 3\n",
    "plt.plot(leftx, ploty, 'o', color='red', markersize=mark_size)\n",
    "plt.plot(rightx, ploty, 'o', color='blue', markersize=mark_size)\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(0, 720)\n",
    "plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "plt.gca().invert_yaxis() # to visualize as we do the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define y-value where we want radius of curvature\n",
    "# I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "y_eval = np.max(ploty)\n",
    "left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "print(left_curverad, right_curverad)\n",
    "# Example values: 1926.74 1908.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "# Fit new polynomials to x,y in world space\n",
    "left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "# Calculate the new radii of curvature\n",
    "left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "# Now our radius of curvature is in meters\n",
    "print(left_curverad, 'm', right_curverad, 'm')\n",
    "# Example values: 632.1 m    626.2 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
